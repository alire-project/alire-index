name = "spark_unbound"
description = "Unbound data structures in Ada-Spark"
version = "0.2.0"

long-description = """
Spark_Unbound is a take on providing generic unbound data structures in Spark.

In addition to proving general absence of runtime errors, the heap allocation is done in a non-Spark function to catch a possible `Storage_Error`.
This further increases the security and confident use of this library.

**The following packages are currently available:**

- `Spark_Unbound.Safe_Alloc`: Providing formally proven safe heap allocation functionality
- `Spark_Unbound.Arrays`: Providing a formally proven alternative to `Ada.Containers.Vector`

**Note:** If you use this library, starring the repository on GitHub helps me a lot to see if it is even useful for someone else.
"""

authors = ["Manuel Hatzl"]
maintainers = ["Manuel Hatzl <hatzlmanuel@outlook.com>"]
maintainers-logins = ["mhatzl"]
website = "https://github.com/mhatzl/spark_unbound"

licenses = "MIT"

tags = ["spark", "unbound"]

[origin]
commit = "624de5708f77ebbb2d2c21f3b04c27b735e5fe63"
url = "git+https://github.com/mhatzl/spark_unbound.git"

